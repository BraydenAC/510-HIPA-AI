{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQtGqysTCXyFh55JtUCwuw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BraydenAC/510-HIPA-AI/blob/Updated-Model/HIPA_AI_Baseline_Formatted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bBazyieUoUm",
        "outputId": "72fadc32-b59a-4670-8c7f-c0457214a760"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (100, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: ['Yes' 'No' 'Yes' 'Yes' 'Yes' 'No' 'No' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes'\n",
            " 'Yes' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'No' 'Yes' 'No' 'No' 'No' 'No'\n",
            " 'No' 'No' 'No' 'Yes']\n",
            "Accuracy: 0.63\n",
            "F1 Score: 0.59\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, f1_score, recall_score, precision_score\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        # Initialize pre-trained BERT\n",
        "        self.model_name = 'bert-base-uncased'\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
        "        self.model = AutoModel.from_pretrained(self.model_name)\n",
        "        self.model.eval()\n",
        "        self.clf = LogisticRegression(max_iter=1000)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Tokenize and encode the text inputs\n",
        "        inputs = self.tokenizer(X, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "        # Train the logistic regression model on the transformed data\n",
        "        self.clf.fit(embeddings, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Transform the new text data using the trained BERT model\n",
        "        inputs = self.tokenizer(X, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "        # Predict labels\n",
        "        return self.clf.predict(embeddings)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/Compiled Annotations CSV.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# Print the shape of the dataset\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "\n",
        "# Extract features and labels\n",
        "X = df['Features'].tolist()\n",
        "y = df['Label'].tolist()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and fit the model\n",
        "model_instance = Model()\n",
        "model_instance.fit(X_train, y_train)\n",
        "\n",
        "# Example prediction\n",
        "predictions = model_instance.predict(X_test)\n",
        "print(f'Predictions: {predictions}')\n",
        "\n",
        "# Calculate accuracy and F1 score\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "f1 = f1_score(y_test, predictions, pos_label='Yes')\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print(f'F1 Score: {f1:.2f}')"
      ]
    }
  ]
}